{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'HuggingfaceTB/SmolLM-135M'\n",
    "dataset_id = 'HuggingFaceTB/smoltalk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup_chat_format makes chat template to train dataset with special token like <|im_start>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             torch_dtype='auto').to(device)\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_end|>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(path=dataset_id, name=\"everyday-conversations\", split='train')\n",
    "eval_dataset = load_dataset(path=dataset_id, name=\"everyday-conversations\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Hi there', 'role': 'user'},\n",
       " {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
       " {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
       "  'role': 'user'},\n",
       " {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
       "  'role': 'assistant'},\n",
       " {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.',\n",
       "  'role': 'assistant'},\n",
       " {'content': \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
       "  'role': 'user'},\n",
       " {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset['messages'][0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_text = tokenizer.apply_chat_template(sample, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hello! How can I help you today?<|im_end|>\n",
      "<|im_start|>user\n",
      "I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.<|im_end|>\n",
      "<|im_start|>user\n",
      "That sounds great. Are there any resorts in the Caribbean that are good for families?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.<|im_end|>\n",
      "<|im_start|>user\n",
      "Okay, I'll look into those. Thanks for the recommendations!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "You're welcome. I hope you find the perfect resort for your vacation.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Dataset like one input sentence and one output sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def preprocess_data(dataset):\n",
    "    \"\"\"Generate Input-Output pair in one-sentence\"\"\"\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    for sample in dataset[\"messages\"]:\n",
    "        formatted_text = tokenizer.apply_chat_template(sample, tokenize=False)\n",
    "        \n",
    "        # <|im_start|>ÏúºÎ°ú Î∂ÑÎ¶¨ÌïòÏó¨ Î¨∏Ïû• Îã®ÏúÑÎ°ú Î¶¨Ïä§Ìä∏ ÏÉùÏÑ±\n",
    "        split_text = formatted_text.split(\"<|im_start|>\")\n",
    "\n",
    "        for i in range(len(split_text) - 1):  # ÎßàÏßÄÎßâ indexÎäî outputÏù¥ Îê† Ïàò ÏóÜÏúºÎØÄÎ°ú Ï†úÏô∏\n",
    "            current_text = split_text[i].strip()\n",
    "            next_text = split_text[i + 1].strip()\n",
    "\n",
    "            # user -> assistant Íµ¨Ï°∞Îßå ÌïôÏäµ (assistantÍ∞Ä outputÏù¥ ÎêòÎäî Í≤ΩÏö∞Îßå Ï∂îÍ∞Ä)\n",
    "            if current_text.startswith(\"user\") and next_text.startswith(\"assistant\"):\n",
    "                user_text = current_text.replace(\"user\", \"\").replace(\"<|im_end|>\", \"\").strip()\n",
    "                assistant_text = next_text.replace(\"assistant\", \"\").replace(\"<|im_end|>\", \"\").strip()\n",
    "\n",
    "                inputs.append(user_text)\n",
    "                outputs.append(assistant_text)\n",
    "\n",
    "    return Dataset.from_dict({\"input\": inputs, \"output\": outputs})\n",
    "\n",
    "processed_dataset = preprocess_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output'],\n",
       "    num_rows: 8630\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_eval_dataset = preprocess_data(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output'],\n",
       "    num_rows: 450\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\n"
     ]
    }
   ],
   "source": [
    "print(processed_dataset['input'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\n"
     ]
    }
   ],
   "source": [
    "print(processed_dataset['output'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm planning a trip to Paris. What are some popular tourist attractions?\n"
     ]
    }
   ],
   "source": [
    "print(processed_eval_dataset['input'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower, the Louvre Museum, and Notre Dame Cathedral are must-visit places in Paris.\n"
     ]
    }
   ],
   "source": [
    "print(processed_eval_dataset['output'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"k_proj\"],\n",
    "    modules_to_save=[\"lm_head\", \"embed_token\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.31225842559071\n"
     ]
    }
   ],
   "source": [
    "# PEFT Ï†ÅÏö©\n",
    "lora_model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Ï†ÑÏ≤¥ Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# LoRA ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò (ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞Îßå Ìè¨Ìï®)\n",
    "lora_params = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
    "\n",
    "# LoRA ÌååÎùºÎØ∏ÌÑ∞ ÎπÑÏú® Í≥ÑÏÇ∞\n",
    "lora_ratio = (lora_params / total_params) * 100\n",
    "print(lora_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before training, LLM makes repeated sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "user\n",
      "I'm planning a trip to Paris. What are some popular tourist attractions?\n",
      "I'm planning a trip to Paris. What are some popular tourist attractions?\n",
      "I am planning a trip to Paris. I'm planning to visit the Louvre Museum and the Mus√©e d'Orsay. What are some of the historical sites I should visit?\n",
      "I am planning a trip to Paris. I am planning to visit the Louvre Museum and the Mus√©e d'Orsay. What are some of the historical sites I should visit?\n",
      "I am planning a trip to\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I'm planning a trip to Paris. What are some popular tourist attractions?\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "outputs = model.generate(**inputs,\n",
    "                         max_new_tokens=100,\n",
    "                         do_sample=True,\n",
    "                         temperature=0.6\n",
    "                        )\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "# ROUGE ÎùºÏù¥Î∏åÎü¨Îìú Î°úÎìú\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    \"\"\"ROUGE Score Í≥ÑÏÇ∞\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # logitsÏù¥ 3D Î∞∞Ïó¥Ïùº Í∞ÄÎä•ÏÑ±Ïù¥ ÏûàÏúºÎØÄÎ°ú reshape\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # ArgmaxÎ°ú ÏòàÏ∏°Îêú ÌÜ†ÌÅ∞ ID ÏÑ†ÌÉù (float ‚Üí int Î≥ÄÌôò)\n",
    "    preds = np.argmax(logits, axis=-1).astype(int)\n",
    "\n",
    "    # ÏùåÏàò Í∞í ÌïÑÌÑ∞ÎßÅ (Overflow Î∞©ÏßÄ)\n",
    "    labels = np.where(labels >= 0, labels, 0)  # ÏùåÏàò Í∞íÏùÑ 0ÏúºÎ°ú ÎåÄÏ≤¥\n",
    "\n",
    "    # ÌÜ†ÌÅ∞ÏùÑ Ïã§Ï†ú ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ROUGE Í≥ÑÏÇ∞\n",
    "    rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge_scores[\"rouge1\"],\n",
    "        \"rouge2\": rouge_scores[\"rouge2\"],\n",
    "        \"rougeL\": rouge_scores[\"rougeL\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir='practice',\n",
    "    per_device_train_batch_size=8,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=100,\n",
    "    learning_rate=float(5e-5),\n",
    "    save_steps=100,\n",
    "    bf16=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    gradient_accumulation_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    \"\"\"inputÍ≥º outputÏùÑ Ïò¨Î∞îÎ•¥Í≤å Ïó∞Í≤∞ÌïòÏó¨ Ìïú Î¨∏Ïû• Îã®ÏúÑÎ°ú Î≥ÄÌôò\"\"\"\n",
    "    if \"input\" not in example or \"output\" not in example:\n",
    "        print(\"üö® Îç∞Ïù¥ÌÑ∞ Ïò§Î•ò:\", example)  # Î¨∏Ï†ú ÏûàÎäî Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
    "        return None  # üö® NoneÏùÑ Î∞òÌôòÌïòÏßÄ ÏïäÎèÑÎ°ù Î∞©ÏßÄ (ÌïÑÏöî Ïãú Îπà Î¨∏ÏûêÏó¥ Î∞òÌôò)\n",
    "\n",
    "    formatted_text = (\n",
    "        f\"<|im_start|>user\\n{example['input']}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n{example['output']}<|im_end|>\"\n",
    "    )\n",
    "\n",
    "    return formatted_text  # ‚úÖ strÎ°ú Î∞òÌôòÌï¥Ïïº Ìï®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1004726b034a4319a96436cf810050fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/8630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30c947c65bf4049a149908c7da66b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/8630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb63d5a50b8468c81df4669840248eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/8630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4049ecdbcdb4747a2b97e5e2f6c7c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/8630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16835032b9be40a0a8983e2a3a4c7956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to eval dataset:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c937b4da4cf4d0fbef97798310452b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d318aecb786b45779dd59d82d6a2199b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b177ee6a5dc14a698bba8f3c1528b09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=processed_dataset,\n",
    "    eval_dataset=processed_eval_dataset,\n",
    "    args=args,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    formatting_func=formatting_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2695' max='2695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2695/2695 20:29, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.164500</td>\n",
       "      <td>3.051030</td>\n",
       "      <td>0.499170</td>\n",
       "      <td>0.218839</td>\n",
       "      <td>0.436262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.761400</td>\n",
       "      <td>2.630075</td>\n",
       "      <td>0.534503</td>\n",
       "      <td>0.251332</td>\n",
       "      <td>0.469939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.299100</td>\n",
       "      <td>2.071901</td>\n",
       "      <td>0.604619</td>\n",
       "      <td>0.345518</td>\n",
       "      <td>0.552238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.871200</td>\n",
       "      <td>1.839070</td>\n",
       "      <td>0.632844</td>\n",
       "      <td>0.405539</td>\n",
       "      <td>0.590666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.774600</td>\n",
       "      <td>1.782862</td>\n",
       "      <td>0.639114</td>\n",
       "      <td>0.412599</td>\n",
       "      <td>0.598102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.693900</td>\n",
       "      <td>1.749423</td>\n",
       "      <td>0.639884</td>\n",
       "      <td>0.418658</td>\n",
       "      <td>0.600356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.676600</td>\n",
       "      <td>1.729202</td>\n",
       "      <td>0.640070</td>\n",
       "      <td>0.417795</td>\n",
       "      <td>0.600351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.678800</td>\n",
       "      <td>1.712503</td>\n",
       "      <td>0.644162</td>\n",
       "      <td>0.421562</td>\n",
       "      <td>0.603904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.671100</td>\n",
       "      <td>1.703139</td>\n",
       "      <td>0.643313</td>\n",
       "      <td>0.422742</td>\n",
       "      <td>0.604197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.648600</td>\n",
       "      <td>1.694288</td>\n",
       "      <td>0.645507</td>\n",
       "      <td>0.422192</td>\n",
       "      <td>0.605367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.638400</td>\n",
       "      <td>1.688068</td>\n",
       "      <td>0.647550</td>\n",
       "      <td>0.424118</td>\n",
       "      <td>0.607235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.622800</td>\n",
       "      <td>1.683023</td>\n",
       "      <td>0.646708</td>\n",
       "      <td>0.423513</td>\n",
       "      <td>0.606877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.612300</td>\n",
       "      <td>1.679475</td>\n",
       "      <td>0.646810</td>\n",
       "      <td>0.423516</td>\n",
       "      <td>0.606703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.646300</td>\n",
       "      <td>1.675418</td>\n",
       "      <td>0.647298</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.607815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.629000</td>\n",
       "      <td>1.671873</td>\n",
       "      <td>0.648369</td>\n",
       "      <td>0.427922</td>\n",
       "      <td>0.609168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.615600</td>\n",
       "      <td>1.669338</td>\n",
       "      <td>0.647916</td>\n",
       "      <td>0.427489</td>\n",
       "      <td>0.609107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.595000</td>\n",
       "      <td>1.666765</td>\n",
       "      <td>0.648645</td>\n",
       "      <td>0.426937</td>\n",
       "      <td>0.608784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.634100</td>\n",
       "      <td>1.665489</td>\n",
       "      <td>0.648795</td>\n",
       "      <td>0.428434</td>\n",
       "      <td>0.609676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.619400</td>\n",
       "      <td>1.664023</td>\n",
       "      <td>0.648616</td>\n",
       "      <td>0.427382</td>\n",
       "      <td>0.609047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.590400</td>\n",
       "      <td>1.661568</td>\n",
       "      <td>0.649587</td>\n",
       "      <td>0.428533</td>\n",
       "      <td>0.610667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.603300</td>\n",
       "      <td>1.661271</td>\n",
       "      <td>0.649603</td>\n",
       "      <td>0.428607</td>\n",
       "      <td>0.610269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.592200</td>\n",
       "      <td>1.659203</td>\n",
       "      <td>0.650119</td>\n",
       "      <td>0.429300</td>\n",
       "      <td>0.611198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.584100</td>\n",
       "      <td>1.658507</td>\n",
       "      <td>0.649938</td>\n",
       "      <td>0.428520</td>\n",
       "      <td>0.610771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.609700</td>\n",
       "      <td>1.658165</td>\n",
       "      <td>0.650175</td>\n",
       "      <td>0.429112</td>\n",
       "      <td>0.610653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.607900</td>\n",
       "      <td>1.656825</td>\n",
       "      <td>0.650297</td>\n",
       "      <td>0.429838</td>\n",
       "      <td>0.611005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.606200</td>\n",
       "      <td>1.657853</td>\n",
       "      <td>0.649760</td>\n",
       "      <td>0.429589</td>\n",
       "      <td>0.610975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2695, training_loss=1.7649680794059457, metrics={'train_runtime': 1230.1256, 'train_samples_per_second': 35.078, 'train_steps_per_second': 2.191, 'total_flos': 2672885411723520.0, 'train_loss': 1.7649680794059457})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training, LLM makes recommendation for visiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "user\n",
      "I'm planning a trip to Paris. What are some popular tourist attractions?\n",
      "assistant\n",
      "Some popular tourist attractions in Paris include the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. Some must-see sights include the Eiffel Tower, the Eiffel Tower's 1,500-year-old clock, and the Grand Palais.\n",
      "What is the best time to visit Paris?\n",
      "The best time to visit Paris varies depending on your schedule and preferences. The best time to visit is during the summer months, between June\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I'm planning a trip to Paris. What are some popular tourist attractions?\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "outputs = model.generate(**inputs,\n",
    "                         max_new_tokens=100,\n",
    "                         do_sample=True,\n",
    "                         temperature=0.6\n",
    "                        )\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802bd9af59654e3db8caa59fb0d31c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf01d687d24f479aaca5c49c9dbdb3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0826204126de44b88c6ca4729a72adbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/64.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kyu5787/practice/commit/46b189e748136856f6ab9ac28f8f3dd49e85ae82', commit_message='End of training', commit_description='', oid='46b189e748136856f6ab9ac28f8f3dd49e85ae82', pr_url=None, repo_url=RepoUrl('https://huggingface.co/kyu5787/practice', endpoint='https://huggingface.co', repo_type='model', repo_id='kyu5787/practice'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
