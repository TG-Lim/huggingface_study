{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'HuggingfaceTB/SmolLM-135M'\n",
    "dataset_id = 'HuggingFaceTB/smoltalk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup_chat_format makes chat template to train dataset with special token like <|im_start>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             torch_dtype='auto').to(device)\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_end|>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(path=dataset_id, name=\"everyday-conversations\", split='train')\n",
    "eval_dataset = load_dataset(path=dataset_id, name=\"everyday-conversations\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Hi there', 'role': 'user'},\n",
       " {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
       " {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
       "  'role': 'user'},\n",
       " {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
       "  'role': 'assistant'},\n",
       " {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.',\n",
       "  'role': 'assistant'},\n",
       " {'content': \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
       "  'role': 'user'},\n",
       " {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset['messages'][0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_text = tokenizer.apply_chat_template(sample, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hello! How can I help you today?<|im_end|>\n",
      "<|im_start|>user\n",
      "I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.<|im_end|>\n",
      "<|im_start|>user\n",
      "That sounds great. Are there any resorts in the Caribbean that are good for families?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.<|im_end|>\n",
      "<|im_start|>user\n",
      "Okay, I'll look into those. Thanks for the recommendations!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "You're welcome. I hope you find the perfect resort for your vacation.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Dataset like one input sentence and one output sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def preprocess_data(dataset):\n",
    "    \"\"\"Generate Input-Output pair in one-sentence\"\"\"\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    for sample in dataset[\"messages\"]:\n",
    "        formatted_text = tokenizer.apply_chat_template(sample, tokenize=False)\n",
    "        \n",
    "        # <|im_start|>으로 분리하여 문장 단위로 리스트 생성\n",
    "        split_text = formatted_text.split(\"<|im_start|>\")\n",
    "\n",
    "        for i in range(len(split_text) - 1):  # 마지막 index는 output이 될 수 없으므로 제외\n",
    "            current_text = split_text[i].strip()\n",
    "            next_text = split_text[i + 1].strip()\n",
    "\n",
    "            # user -> assistant 구조만 학습 (assistant가 output이 되는 경우만 추가)\n",
    "            if current_text.startswith(\"user\") and next_text.startswith(\"assistant\"):\n",
    "                user_text = current_text.replace(\"user\", \"\").replace(\"<|im_end|>\", \"\").strip()\n",
    "                assistant_text = next_text.replace(\"assistant\", \"\").replace(\"<|im_end|>\", \"\").strip()\n",
    "\n",
    "                inputs.append(user_text)\n",
    "                outputs.append(assistant_text)\n",
    "\n",
    "    return Dataset.from_dict({\"input\": inputs, \"output\": outputs})\n",
    "\n",
    "processed_dataset = preprocess_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output'],\n",
       "    num_rows: 8630\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_eval_dataset = preprocess_data(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output'],\n",
       "    num_rows: 450\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\n"
     ]
    }
   ],
   "source": [
    "print(processed_dataset['input'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\n"
     ]
    }
   ],
   "source": [
    "print(processed_dataset['output'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm planning a trip to Paris. What are some popular tourist attractions?\n"
     ]
    }
   ],
   "source": [
    "print(processed_eval_dataset['input'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower, the Louvre Museum, and Notre Dame Cathedral are must-visit places in Paris.\n"
     ]
    }
   ],
   "source": [
    "print(processed_eval_dataset['output'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"k_proj\"],\n",
    "    modules_to_save=[\"lm_head\", \"embed_token\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.31225842559071\n"
     ]
    }
   ],
   "source": [
    "# PEFT 적용\n",
    "lora_model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 전체 모델 파라미터 개수\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# LoRA 파라미터 개수 (학습 가능한 파라미터만 포함)\n",
    "lora_params = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
    "\n",
    "# LoRA 파라미터 비율 계산\n",
    "lora_ratio = (lora_params / total_params) * 100\n",
    "print(lora_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before training, LLM makes repeated sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "user\n",
      "I'm planning a trip to Paris. What are some popular tourist attractions?\n",
      "I'm planning a trip to Paris. What are some popular tourist attractions?\n",
      "I am planning a trip to Paris. I'm planning to visit the Louvre Museum and the Musée d'Orsay. What are some of the historical sites I should visit?\n",
      "I am planning a trip to Paris. I am planning to visit the Louvre Museum and the Musée d'Orsay. What are some of the historical sites I should visit?\n",
      "I am planning a trip to\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I'm planning a trip to Paris. What are some popular tourist attractions?\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "outputs = model.generate(**inputs,\n",
    "                         max_new_tokens=100,\n",
    "                         do_sample=True,\n",
    "                         temperature=0.6\n",
    "                        )\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "# ROUGE 라이브러드 로드\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    \"\"\"ROUGE Score 계산\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # logits이 3D 배열일 가능성이 있으므로 reshape\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # Argmax로 예측된 토큰 ID 선택 (float → int 변환)\n",
    "    preds = np.argmax(logits, axis=-1).astype(int)\n",
    "\n",
    "    # 음수 값 필터링 (Overflow 방지)\n",
    "    labels = np.where(labels >= 0, labels, 0)  # 음수 값을 0으로 대체\n",
    "\n",
    "    # 토큰을 실제 텍스트로 변환\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ROUGE 계산\n",
    "    rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge_scores[\"rouge1\"],\n",
    "        \"rouge2\": rouge_scores[\"rouge2\"],\n",
    "        \"rougeL\": rouge_scores[\"rougeL\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir='practice',\n",
    "    per_device_train_batch_size=8,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=100,\n",
    "    learning_rate=float(5e-5),\n",
    "    save_steps=100,\n",
    "    bf16=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    gradient_accumulation_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    \"\"\"input과 output을 올바르게 연결하여 한 문장 단위로 변환\"\"\"\n",
    "    if \"input\" not in example or \"output\" not in example:\n",
    "        print(\"🚨 데이터 오류:\", example)  # 문제 있는 데이터 확인\n",
    "        return None  # 🚨 None을 반환하지 않도록 방지 (필요 시 빈 문자열 반환)\n",
    "\n",
    "    formatted_text = (\n",
    "        f\"<|im_start|>user\\n{example['input']}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n{example['output']}<|im_end|>\"\n",
    "    )\n",
    "\n",
    "    return formatted_text  # ✅ str로 반환해야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1004726b034a4319a96436cf810050fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/8630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30c947c65bf4049a149908c7da66b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/8630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb63d5a50b8468c81df4669840248eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/8630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4049ecdbcdb4747a2b97e5e2f6c7c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/8630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16835032b9be40a0a8983e2a3a4c7956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to eval dataset:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c937b4da4cf4d0fbef97798310452b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d318aecb786b45779dd59d82d6a2199b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b177ee6a5dc14a698bba8f3c1528b09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=processed_dataset,\n",
    "    eval_dataset=processed_eval_dataset,\n",
    "    args=args,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    formatting_func=formatting_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2695' max='2695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2695/2695 20:29, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.164500</td>\n",
       "      <td>3.051030</td>\n",
       "      <td>0.499170</td>\n",
       "      <td>0.218839</td>\n",
       "      <td>0.436262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.761400</td>\n",
       "      <td>2.630075</td>\n",
       "      <td>0.534503</td>\n",
       "      <td>0.251332</td>\n",
       "      <td>0.469939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.299100</td>\n",
       "      <td>2.071901</td>\n",
       "      <td>0.604619</td>\n",
       "      <td>0.345518</td>\n",
       "      <td>0.552238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.871200</td>\n",
       "      <td>1.839070</td>\n",
       "      <td>0.632844</td>\n",
       "      <td>0.405539</td>\n",
       "      <td>0.590666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.774600</td>\n",
       "      <td>1.782862</td>\n",
       "      <td>0.639114</td>\n",
       "      <td>0.412599</td>\n",
       "      <td>0.598102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.693900</td>\n",
       "      <td>1.749423</td>\n",
       "      <td>0.639884</td>\n",
       "      <td>0.418658</td>\n",
       "      <td>0.600356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.676600</td>\n",
       "      <td>1.729202</td>\n",
       "      <td>0.640070</td>\n",
       "      <td>0.417795</td>\n",
       "      <td>0.600351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.678800</td>\n",
       "      <td>1.712503</td>\n",
       "      <td>0.644162</td>\n",
       "      <td>0.421562</td>\n",
       "      <td>0.603904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.671100</td>\n",
       "      <td>1.703139</td>\n",
       "      <td>0.643313</td>\n",
       "      <td>0.422742</td>\n",
       "      <td>0.604197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.648600</td>\n",
       "      <td>1.694288</td>\n",
       "      <td>0.645507</td>\n",
       "      <td>0.422192</td>\n",
       "      <td>0.605367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.638400</td>\n",
       "      <td>1.688068</td>\n",
       "      <td>0.647550</td>\n",
       "      <td>0.424118</td>\n",
       "      <td>0.607235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.622800</td>\n",
       "      <td>1.683023</td>\n",
       "      <td>0.646708</td>\n",
       "      <td>0.423513</td>\n",
       "      <td>0.606877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.612300</td>\n",
       "      <td>1.679475</td>\n",
       "      <td>0.646810</td>\n",
       "      <td>0.423516</td>\n",
       "      <td>0.606703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.646300</td>\n",
       "      <td>1.675418</td>\n",
       "      <td>0.647298</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.607815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.629000</td>\n",
       "      <td>1.671873</td>\n",
       "      <td>0.648369</td>\n",
       "      <td>0.427922</td>\n",
       "      <td>0.609168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.615600</td>\n",
       "      <td>1.669338</td>\n",
       "      <td>0.647916</td>\n",
       "      <td>0.427489</td>\n",
       "      <td>0.609107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.595000</td>\n",
       "      <td>1.666765</td>\n",
       "      <td>0.648645</td>\n",
       "      <td>0.426937</td>\n",
       "      <td>0.608784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.634100</td>\n",
       "      <td>1.665489</td>\n",
       "      <td>0.648795</td>\n",
       "      <td>0.428434</td>\n",
       "      <td>0.609676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.619400</td>\n",
       "      <td>1.664023</td>\n",
       "      <td>0.648616</td>\n",
       "      <td>0.427382</td>\n",
       "      <td>0.609047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.590400</td>\n",
       "      <td>1.661568</td>\n",
       "      <td>0.649587</td>\n",
       "      <td>0.428533</td>\n",
       "      <td>0.610667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.603300</td>\n",
       "      <td>1.661271</td>\n",
       "      <td>0.649603</td>\n",
       "      <td>0.428607</td>\n",
       "      <td>0.610269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.592200</td>\n",
       "      <td>1.659203</td>\n",
       "      <td>0.650119</td>\n",
       "      <td>0.429300</td>\n",
       "      <td>0.611198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.584100</td>\n",
       "      <td>1.658507</td>\n",
       "      <td>0.649938</td>\n",
       "      <td>0.428520</td>\n",
       "      <td>0.610771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.609700</td>\n",
       "      <td>1.658165</td>\n",
       "      <td>0.650175</td>\n",
       "      <td>0.429112</td>\n",
       "      <td>0.610653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.607900</td>\n",
       "      <td>1.656825</td>\n",
       "      <td>0.650297</td>\n",
       "      <td>0.429838</td>\n",
       "      <td>0.611005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.606200</td>\n",
       "      <td>1.657853</td>\n",
       "      <td>0.649760</td>\n",
       "      <td>0.429589</td>\n",
       "      <td>0.610975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2695, training_loss=1.7649680794059457, metrics={'train_runtime': 1230.1256, 'train_samples_per_second': 35.078, 'train_steps_per_second': 2.191, 'total_flos': 2672885411723520.0, 'train_loss': 1.7649680794059457})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training, LLM makes recommendation for visiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "user\n",
      "I'm planning a trip to Paris. What are some popular tourist attractions?\n",
      "assistant\n",
      "Some popular tourist attractions in Paris include the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. Some must-see sights include the Eiffel Tower, the Eiffel Tower's 1,500-year-old clock, and the Grand Palais.\n",
      "What is the best time to visit Paris?\n",
      "The best time to visit Paris varies depending on your schedule and preferences. The best time to visit is during the summer months, between June\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I'm planning a trip to Paris. What are some popular tourist attractions?\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "outputs = model.generate(**inputs,\n",
    "                         max_new_tokens=100,\n",
    "                         do_sample=True,\n",
    "                         temperature=0.6\n",
    "                        )\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802bd9af59654e3db8caa59fb0d31c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf01d687d24f479aaca5c49c9dbdb3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0826204126de44b88c6ca4729a72adbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/64.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kyu5787/practice/commit/46b189e748136856f6ab9ac28f8f3dd49e85ae82', commit_message='End of training', commit_description='', oid='46b189e748136856f6ab9ac28f8f3dd49e85ae82', pr_url=None, repo_url=RepoUrl('https://huggingface.co/kyu5787/practice', endpoint='https://huggingface.co', repo_type='model', repo_id='kyu5787/practice'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
